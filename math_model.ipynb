{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import gensim #For word2vec\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "import nltk\n",
    "import random\n",
    "from numpy.random import choice as randomchoice\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import sys\n",
    "# import torchtext\n",
    "import pickle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import torchtext.vocab as vocab\n",
    "glove_model = api.load(\"glove-wiki-gigaword-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_start_time = time.time();\n",
    "# val_file = sys.argv[2];\n",
    "train_file = 'data/train.json'\n",
    "val_file = 'data/dev.json'\n",
    "test_file = 'data/test.json'\n",
    "\n",
    "tokenize_func = nltk.tokenize.WordPunctTokenizer().tokenize\n",
    "punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "def is_numeric(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError: #Classic way to get is_numeric\n",
    "        return False\n",
    "def tokenize(sentence, with_num = False):\n",
    "    old = tokenize_func(sentence.lower());\n",
    "    s = [];\n",
    "    for word in old:\n",
    "        running = [];\n",
    "        for character in word:\n",
    "            if(character in punctuations):\n",
    "                if(len(running) > 0):\n",
    "                    s.append(''.join(running));\n",
    "                    running = []; #emptying the running list.\n",
    "                s.append(character); #then adding the punctuation.\n",
    "            else:\n",
    "                running.append(character);\n",
    "        if(len(running) > 0):\n",
    "            s.append(''.join(running));\n",
    "        #this above code ensures that what we have is also split on punctuation\n",
    "    if(with_num):\n",
    "        return s; #If with_num is true, return the sentence as it is, without converting the numbers to <NUM>\n",
    "    for i in range(len(s)):\n",
    "        if(is_numeric(s[i])):\n",
    "            s[i] = '<NUM>'; #replaces numbers with <NUM>\n",
    "    return s;\n",
    "\n",
    "def tokenize_with_num(sentence): #just tokenizes normally. No replacement of numbers\n",
    "    s = tokenize_func(sentence.lower());\n",
    "    return s;\n",
    "\n",
    "def get_embedding_index(sentences, model):\n",
    "    return ([tokenize_and_get_embedding_index(sentence, model) for sentence in sentences]);\n",
    "\n",
    "def tokenize_and_get_embedding_index(sentence, vocab, with_num = False):\n",
    "    s = tokenize(sentence, with_num = with_num);\n",
    "    # FOr now testing with No UNK, Later will have to add UNK\n",
    "    tens = torch.tensor([vocab.get(word, vocab['<UNK>']) for word in s]) # if (word in vocab)]); #if the word is not in the punctuation, only then we add it.\n",
    "    return tens;\n",
    "    if(len(tens) == 0):\n",
    "        return torch.tensor([vocab.get(word, vocab['<UNK>']) for word in s]) #using UNK in this case.\n",
    "    else:\n",
    "        return tens;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file) as f:\n",
    "    train_data = json.load(f)\n",
    "with open(val_file) as f:\n",
    "    val_data = json.load(f)\n",
    "with open(test_file) as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sophia finished 2 / 3 of a book . she calculated that she finished 90 more pages than she has yet to read . how long is her book ?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]['Problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Postprocessing the code to remove the last '|' that is sometimes randomly present.\n",
    "def remove_last_extra(data):\n",
    "    for i in range(len(data)):\n",
    "        if(data[i]['linear_formula'][-1] == '|'):\n",
    "            data[i]['linear_formula'] = data[i]['linear_formula'][:-1];\n",
    "        \n",
    "    return data; #although not really needed.\n",
    "remove_last_extra(val_data);\n",
    "remove_last_extra(train_data);\n",
    "remove_last_extra(test_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(['<START>', '<END>', '<PAD>', '<UNK>', '<NUM>']);\n",
    "for data in train_data:\n",
    "    for word in tokenize(data['Problem']):\n",
    "        vocabulary.add(word);\n",
    "    for word in tokenize(data['linear_formula']):\n",
    "        vocabulary.add(word);\n",
    "vocab_word_to_index = {word: i for i, word in enumerate(vocabulary)};\n",
    "vocab_index_to_word = {i: word for i, word in enumerate(vocabulary)};\n",
    "rand_count = 0;\n",
    "def get_word_embedding(word, glove_vectors, dim):\n",
    "    global rand_count;\n",
    "    if word in glove_vectors.key_to_index: #if the key is present we initialize it as glove embedding\n",
    "        return torch.tensor(glove_vectors[word])\n",
    "    else:\n",
    "        rand_count += 1;\n",
    "        return torch.rand(dim)  # Initialize randomly for out-of-vocabulary words\n",
    "start_index = vocab_word_to_index['<START>'];\n",
    "pad_index = vocab_word_to_index['<PAD>'];\n",
    "end_index = vocab_word_to_index['<END>'];\n",
    "unk_index = vocab_word_to_index['<UNK>'];\n",
    "num_index = vocab_word_to_index['<NUM>'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random count is  427  out of  7408\n"
     ]
    }
   ],
   "source": [
    "wordvec = [0] * len(vocabulary); #initializing the wordvec list\n",
    "rand_count = 0;\n",
    "for i in range(len(vocabulary)):\n",
    "    wordvec[i] = get_word_embedding(vocab_index_to_word[i], glove_model, 200);\n",
    "wordvec = torch.stack(wordvec); #stacking the list of tensors to form a tensor.\n",
    "print(\"Random count is \", rand_count, \" out of \", len(vocabulary));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mysaved.pkl', 'wb') as f:\n",
    "    pickle.dump([vocab_word_to_index, vocab_index_to_word, wordvec], f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_on_words(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, wordvectors, padding_index,bidirectional=True, dropout=0.0):\n",
    "        super(LSTM_on_words, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(wordvectors), padding_idx=padding_index,freeze=True).to(device);\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True, bidirectional=bidirectional).to(device);\n",
    "\n",
    "    def forward(self, x, x_lengths):\n",
    "        # Embedding\n",
    "        out = self.embedding(x)\n",
    "        # Pack padded sequence\n",
    "        # lengths = x_lengths.detach().cpu().numpy();\n",
    "        out = pack_padded_sequence(out, x_lengths, batch_first=True, enforce_sorted=False).to(device);\n",
    "        out, (hidden, cell) = self.lstm(out)\n",
    "        # Unpack packed sequence\n",
    "        out, _ = pad_packed_sequence(out, batch_first=True)\n",
    "        return out, (hidden, cell);\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_size, layer_sizes):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.layers = [];\n",
    "        self.ReLU = nn.ReLU(inplace=False)\n",
    "        for i in range(len(layer_sizes)):\n",
    "            if(i == 0):\n",
    "                self.layers.append(nn.Linear(input_size, layer_sizes[i]));\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(layer_sizes[i-1], layer_sizes[i]));\n",
    "            if(i != len(layer_sizes) - 1): #add Relu only if its not the last layer, since that is the output layer that we will softmax over.\n",
    "                self.layers.append(self.ReLU);\n",
    "        self.all_layers = nn.Sequential(*self.layers)\n",
    "    def forward(self, x):\n",
    "        out = self.all_layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mathDataset(Dataset):\n",
    "    def __init__(self, data, vocab_word_to_index, vocab_index_to_word, wordvec):\n",
    "        self.data = data;\n",
    "        self.vocab_word_to_index = vocab_word_to_index;\n",
    "        self.vocab_index_to_word = vocab_index_to_word;\n",
    "        self.wordvec = wordvec;\n",
    "    def __len__(self):\n",
    "        return len(self.data);\n",
    "    def __getitem__(self, idx):\n",
    "        problem = self.data[idx]['Problem'] + \" <END>\";\n",
    "        linear_formula = self.data[idx]['linear_formula'] + \" <END>\"; #maybe the linear formula can go directly without getting emebdded as well.\n",
    "        problem = tokenize_and_get_embedding_index(problem, self.vocab_word_to_index);\n",
    "        linear_formula = tokenize_and_get_embedding_index(linear_formula, self.vocab_word_to_index);\n",
    "        return problem, linear_formula;\n",
    "\n",
    "def collate_fn(data):\n",
    "    # data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    problems, linear_formulas = zip(*data)\n",
    "    # problems = data; #zip(*data)\n",
    "    problems_lengths = [len(problem) for problem in problems]\n",
    "    # linear_formulas = pad_sequence\n",
    "    problems = pad_sequence(problems, batch_first=True, padding_value=vocab_word_to_index['<PAD>'])\n",
    "    linear_formulas = pad_sequence(linear_formulas, batch_first=True, padding_value=vocab_word_to_index['<PAD>'])\n",
    "    return problems, problems_lengths, linear_formulas;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32;\n",
    "dataloader = DataLoader(mathDataset(train_data, vocab_word_to_index, vocab_index_to_word, wordvec), batch_size=batch_size, shuffle=True, collate_fn=collate_fn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LSTM_on_words(200, 200, 2, wordvec, vocab_word_to_index['<PAD>'], bidirectional=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so our encoder is simply LSTM_on_words. Now to make the decoder LSTM_on_words.\n",
    "class Decoder_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, wordvectors, padding_index, dropout=0.0):\n",
    "        super(Decoder_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(wordvectors), padding_idx=padding_index,freeze=True).to(device);\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True).to(device);\n",
    "        self.fc = FeedForward(hidden_size,[len(wordvectors)//2,len(wordvectors)]).to(device);\n",
    "    def forward(self, batch_size,max_len, hidden, cell):\n",
    "        dec_in = torch.tensor([vocab_word_to_index['<START>']] * batch_size).unsqueeze(1).to(device);\n",
    "        #dec_in = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(start_index);\n",
    "        outputs = [];\n",
    "        for i in range(max_len):\n",
    "            dec_out, (hidden, cell) = self.forward_step(dec_in,hidden, cell); #we get the value after one step of the LSTM.\n",
    "            outputs.append(dec_out);\n",
    "            _, ind = dec_out.topk(1);\n",
    "            dec_in = ind.squeeze(-1).detach(); #squeezing is necessary because there will be an extra dimension here. Detaching it from the next step.\n",
    "            break;\n",
    "        torch.cat(outputs, dim=1)\n",
    "        return outputs, (hidden, cell)\n",
    "    \n",
    "    def forward_step(self, inputs, hidden, cell):\n",
    "        outs = self.embedding(inputs);\n",
    "        outs, (h, c)  = self.lstm(outs, (hidden, cell));\n",
    "        outs = self.fc(outs); #\n",
    "        return outs, (h, c);\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder_LSTM(200, 400, 1, wordvec, vocab_word_to_index['<PAD>']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs, (h, c) = decoder(batch_size,enc_out.shape[1], hidden, c_enc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (problems, problems_lengths, linear_formulas) in enumerate(dataloader):\n",
    "    problems = problems.to(device);\n",
    "    # problems_lengths = torch.tensor(problems_lengths).to(device);\n",
    "    linear_formulas = linear_formulas.to(device);\n",
    "    enc_out, (h_enc, c_enc) = encoder(problems, problems_lengths);\n",
    "    hidden = h_enc.view(h_enc.shape[0]//2, 2, h_enc.shape[1], -1)[-1];\n",
    "    hidden = torch.cat((hidden[0], hidden[1]), dim=-1).unsqueeze(0); #reverse and forward direction.\n",
    "    cell = c_enc.view(c_enc.shape[0]//2, 2, c_enc.shape[1], -1)[-1];\n",
    "    cell = torch.cat((cell[0], cell[1]), dim=-1).unsqueeze(0); #reverse and forward direction.\n",
    "    outs, (h, c) = decoder(batch_size,enc_out.shape[1], hidden, cell);\n",
    "    #outs = decoder(batch_size,enc_out.shape[1], hidden, cell);\n",
    "    #the first type of decoder does not have any attention system, so what it will do is simply take the last hidden state of the encoder and decipher it further based on that.\n",
    "    \n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0036, -0.0033,  0.0361,  ..., -0.0204,  0.0054,  0.0127],\n",
       "        [ 0.0072,  0.0038,  0.0342,  ..., -0.0235,  0.0066,  0.0128],\n",
       "        [ 0.0057, -0.0016,  0.0341,  ..., -0.0192,  0.0080,  0.0130],\n",
       "        ...,\n",
       "        [ 0.0045,  0.0014,  0.0304,  ..., -0.0213,  0.0028,  0.0141],\n",
       "        [ 0.0064,  0.0013,  0.0310,  ..., -0.0229,  0.0049,  0.0171],\n",
       "        [ 0.0073,  0.0035,  0.0326,  ..., -0.0199,  0.0030,  0.0130]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(outs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6383, 0.5898, 0.7385, 0.9220],\n",
       "         [0.1873, 0.0257, 0.0542, 0.7946],\n",
       "         [0.6523, 0.4925, 0.2044, 0.7247]],\n",
       "\n",
       "        [[0.9574, 0.5743, 0.0913, 0.9562],\n",
       "         [0.6762, 0.9488, 0.2844, 0.8574],\n",
       "         [0.0997, 0.9355, 0.6662, 0.8578]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand((2,3,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9574, 0.6762, 0.0997])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9574, 0.5743, 0.0913])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,4,3)[-1][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
